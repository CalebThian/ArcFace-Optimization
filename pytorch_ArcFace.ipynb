{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "474e277c",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10f17963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model import FaceMobileNet,myFaceMobileNet\n",
    "from model.metric import ArcFace, CosFace\n",
    "from model.loss import FocalLoss\n",
    "from dataset import load_data\n",
    "from config import Config as conf\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from ptflops import get_model_complexity_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fffc4fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"D:\\Course\\Graduate1\\Data_Science\\hw\\hw5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1d090b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10574Total train images: 18325\n"
     ]
    }
   ],
   "source": [
    "# Data Setup\n",
    "dataloader, class_num = load_data(conf, training=True)\n",
    "embedding_size = conf.embedding_size\n",
    "device = conf.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08bf47d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Setup\n",
    "net = myFaceMobileNet(embedding_size).to(device)\n",
    "\n",
    "if conf.metric == 'arcface':\n",
    "    metric = ArcFace(embedding_size, class_num).to(device)\n",
    "else:\n",
    "    metric = CosFace(embedding_size, class_num).to(device)\n",
    "\n",
    "net = nn.DataParallel(net)\n",
    "metric = nn.DataParallel(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "131a4da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Setup\n",
    "if conf.loss == 'focal_loss':\n",
    "    criterion = FocalLoss(gamma=2)\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if conf.optimizer == 'sgd':\n",
    "    optimizer = optim.SGD([{'params': net.parameters()}, {'params': metric.parameters()}], \n",
    "                            lr=conf.lr, weight_decay=conf.weight_decay)\n",
    "else:\n",
    "    optimizer = optim.Adam([{'params': net.parameters()}, {'params': metric.parameters()}],\n",
    "                            lr=conf.lr, weight_decay=conf.weight_decay)\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=conf.lr_step, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9039da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoints Setup\n",
    "os.makedirs(conf.checkpoints, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5668236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/30: 100%|##########| 287/287 [00:38<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/30, Loss: 0.09242450445890427\n",
      "Test Model: myFMN_0_sample10%.pth\n",
      " Accuracy: 0.558\n",
      "Threshold: 0.478\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|##########| 287/287 [00:32<00:00,  8.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 1.6215300559997559\n",
      "Test Model: myFMN_1_sample10%.pth\n",
      " Accuracy: 0.530\n",
      "Threshold: 0.971\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|##########| 287/287 [00:32<00:00,  8.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Loss: 0.010787849314510822\n",
      "Test Model: myFMN_2_sample10%.pth\n",
      " Accuracy: 0.552\n",
      "Threshold: 0.935\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|##########| 287/287 [00:32<00:00,  8.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Loss: 7.4444990158081055\n",
      "Test Model: myFMN_3_sample10%.pth\n",
      " Accuracy: 0.546\n",
      "Threshold: 0.746\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|##########| 287/287 [00:32<00:00,  8.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Loss: 5.121672438690439e-05\n",
      "Test Model: myFMN_4_sample10%.pth\n",
      " Accuracy: 0.552\n",
      "Threshold: 0.921\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|##########| 287/287 [00:32<00:00,  8.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Loss: 4.027842044830322\n",
      "Test Model: myFMN_5_sample10%.pth\n",
      " Accuracy: 0.539\n",
      "Threshold: 0.992\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|##########| 287/287 [00:32<00:00,  8.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Loss: 1.250727927981643e-05\n",
      "Test Model: myFMN_6_sample10%.pth\n",
      " Accuracy: 0.532\n",
      "Threshold: 0.957\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|##########| 287/287 [00:32<00:00,  8.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Loss: 2.4241514205932617\n",
      "Test Model: myFMN_7_sample10%.pth\n",
      " Accuracy: 0.539\n",
      "Threshold: 0.918\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|##########| 287/287 [00:32<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Loss: 0.5672804117202759\n",
      "Test Model: myFMN_8_sample10%.pth\n",
      " Accuracy: 0.547\n",
      "Threshold: 0.808\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|##########| 287/287 [00:32<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Loss: 4.12794303894043\n",
      "Test Model: myFMN_9_sample10%.pth\n",
      " Accuracy: 0.534\n",
      "Threshold: 0.958\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|##########| 287/287 [00:32<00:00,  8.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Loss: 0.4781588315963745\n",
      "Test Model: myFMN_10_sample10%.pth\n",
      " Accuracy: 0.537\n",
      "Threshold: 0.773\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|##########| 287/287 [00:32<00:00,  8.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Loss: 3.604029417037964\n",
      "Test Model: myFMN_11_sample10%.pth\n",
      " Accuracy: 0.539\n",
      "Threshold: 0.803\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|##########| 287/287 [00:32<00:00,  8.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Loss: 0.17157980799674988\n",
      "Test Model: myFMN_12_sample10%.pth\n",
      " Accuracy: 0.541\n",
      "Threshold: 0.838\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: 100%|##########| 287/287 [00:32<00:00,  8.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30, Loss: 7.0279541015625\n",
      "Test Model: myFMN_13_sample10%.pth\n",
      " Accuracy: 0.536\n",
      "Threshold: 0.810\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: 100%|##########| 287/287 [00:32<00:00,  8.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30, Loss: 0.20764197409152985\n",
      "Test Model: myFMN_14_sample10%.pth\n",
      " Accuracy: 0.531\n",
      "Threshold: 0.760\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: 100%|##########| 287/287 [00:32<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30, Loss: 0.2903079688549042\n",
      "Test Model: myFMN_15_sample10%.pth\n",
      " Accuracy: 0.535\n",
      "Threshold: 0.818\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: 100%|##########| 287/287 [00:32<00:00,  8.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30, Loss: 0.13993732631206512\n",
      "Test Model: myFMN_16_sample10%.pth\n",
      " Accuracy: 0.540\n",
      "Threshold: 0.869\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: 100%|##########| 287/287 [00:32<00:00,  8.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30, Loss: 0.4362316429615021\n",
      "Test Model: myFMN_17_sample10%.pth\n",
      " Accuracy: 0.538\n",
      "Threshold: 0.847\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: 100%|##########| 287/287 [00:32<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30, Loss: 1.659886765992269e-05\n",
      "Test Model: myFMN_18_sample10%.pth\n",
      " Accuracy: 0.537\n",
      "Threshold: 0.891\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: 100%|##########| 287/287 [00:32<00:00,  8.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30, Loss: 0.19764065742492676\n",
      "Test Model: myFMN_19_sample10%.pth\n",
      " Accuracy: 0.548\n",
      "Threshold: 0.847\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: 100%|##########| 287/287 [00:32<00:00,  8.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30, Loss: 3.047953032364603e-05\n",
      "Test Model: myFMN_20_sample10%.pth\n",
      " Accuracy: 0.541\n",
      "Threshold: 0.886\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: 100%|##########| 287/287 [00:32<00:00,  8.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30, Loss: 0.15045003592967987\n",
      "Test Model: myFMN_21_sample10%.pth\n",
      " Accuracy: 0.545\n",
      "Threshold: 0.860\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: 100%|##########| 287/287 [00:32<00:00,  8.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30, Loss: 0.00010764157923404127\n",
      "Test Model: myFMN_22_sample10%.pth\n",
      " Accuracy: 0.547\n",
      "Threshold: 0.830\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: 100%|##########| 287/287 [00:32<00:00,  8.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30, Loss: 0.13783210515975952\n",
      "Test Model: myFMN_23_sample10%.pth\n",
      " Accuracy: 0.546\n",
      "Threshold: 0.851\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: 100%|##########| 287/287 [00:32<00:00,  8.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30, Loss: 0.12723605334758759\n",
      "Test Model: myFMN_24_sample10%.pth\n",
      " Accuracy: 0.541\n",
      "Threshold: 0.845\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: 100%|##########| 287/287 [00:32<00:00,  8.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30, Loss: 0.0011353755835443735\n",
      "Test Model: myFMN_25_sample10%.pth\n",
      " Accuracy: 0.539\n",
      "Threshold: 0.873\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: 100%|##########| 287/287 [00:32<00:00,  8.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30, Loss: 1.2327559488767292e-05\n",
      "Test Model: myFMN_26_sample10%.pth\n",
      " Accuracy: 0.542\n",
      "Threshold: 0.873\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30: 100%|##########| 287/287 [00:32<00:00,  8.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30, Loss: 0.20878396928310394\n",
      "Test Model: myFMN_27_sample10%.pth\n",
      " Accuracy: 0.538\n",
      "Threshold: 0.915\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: 100%|##########| 287/287 [00:32<00:00,  8.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30, Loss: 0.17809227108955383\n",
      "Test Model: myFMN_28_sample10%.pth\n",
      " Accuracy: 0.543\n",
      "Threshold: 0.784\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: 100%|##########| 287/287 [00:32<00:00,  8.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30, Loss: 0.11812622100114822\n",
      "Test Model: myFMN_29_sample10%.pth\n",
      " Accuracy: 0.541\n",
      "Threshold: 0.861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "net.train()\n",
    "losses = []\n",
    "#Test at the same time\n",
    "images = unique_image(conf.test_list)\n",
    "images = [osp.join(conf.test_root, img) for img in images]\n",
    "groups = group_image(images, conf.test_batch_size)\n",
    "feature_dict = dict()\n",
    "\n",
    "for e in range(conf.epoch):\n",
    "    #if e<=20:\n",
    "    #    continue\n",
    "    for data, labels in tqdm(dataloader, desc=f\"Epoch {e}/{conf.epoch}\",\n",
    "                             ascii=True, total=len(dataloader)):\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        embeddings = net(data)\n",
    "        thetas = metric(embeddings, labels)\n",
    "        loss = criterion(thetas, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {e}/{conf.epoch}, Loss: {loss}\")\n",
    "    losses.append(loss)\n",
    "    # Test\n",
    "    net.eval()\n",
    "    feature_dict = dict()\n",
    "    for group in groups:\n",
    "        d = featurize(group, conf.test_transform, net, conf.device,low_light = False)\n",
    "        feature_dict.update(d) \n",
    "    accuracy, threshold = compute_accuracy(feature_dict, conf.test_list, conf.test_root) \n",
    "\n",
    "    print(\n",
    "        f\"Test Model: myFMN_{e}_sample{int(conf.train_sample_rate*100)}%.pth\\n\",\n",
    "        f\"Accuracy: {accuracy:.3f}\\n\"\n",
    "        f\"Threshold: {threshold:.3f}\\n\"\n",
    "    )\n",
    "    net.train()\n",
    "    backbone_path = osp.join(conf.checkpoints, f\"myFMN_{e}_sample{int(conf.train_sample_rate*100)}%.pth\")\n",
    "    torch.save(net.state_dict(), backbone_path)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c280358e",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7582ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_image(pair_list) -> set:\n",
    "    \"\"\"Return unique image path in pair_list.txt\"\"\"\n",
    "    with open(pair_list, 'r') as fd:\n",
    "        pairs = fd.readlines()\n",
    "    unique = set()\n",
    "    for pair in pairs:\n",
    "        id1, id2, _ = pair.split()\n",
    "        unique.add(id1)\n",
    "        unique.add(id2)\n",
    "    return unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e031753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_image(images: set, batch) -> list:\n",
    "    \"\"\"Group image paths by batch size\"\"\"\n",
    "    images = list(images)\n",
    "    size = len(images)\n",
    "    res = []\n",
    "    for i in range(0, size, batch):\n",
    "        end = min(batch + i, size)\n",
    "        res.append(images[i : end])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24298711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess(images: list, transform, low_light = False) -> torch.Tensor:\n",
    "    res = []\n",
    "    for img in images:\n",
    "        im = Image.open(img)\n",
    "        if low_light:\n",
    "            im = (np.sqrt (im)*2).astype(np.uint8)\n",
    "            im = Image.fromarray(im)\n",
    "        im = transform(im)\n",
    "        res.append(im)\n",
    "    data = torch.cat(res, dim=0)  # shape: (batch, 128, 128)\n",
    "    data = data[:, None, :, :]    # shape: (batch, 1, 128, 128)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9156a2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize(images: list, transform, net, device,low_light = False) -> dict:\n",
    "    \"\"\"featurize each image and save into a dictionary\n",
    "    Args:\n",
    "        images: image paths\n",
    "        transform: test transform\n",
    "        net: pretrained model\n",
    "        device: cpu or cuda\n",
    "    Returns:\n",
    "        Dict (key: imagePath, value: feature)\n",
    "    \"\"\"\n",
    "    data = _preprocess(images, transform,low_light = low_light)\n",
    "    data = data.to(device)\n",
    "    net = net.to(device)\n",
    "    with torch.no_grad():\n",
    "        features = net(data) \n",
    "    res = {img: feature for (img, feature) in zip(images, features)}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30255a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosin_metric(x1, x2):\n",
    "    return np.dot(x1, x2) / (np.linalg.norm(x1) * np.linalg.norm(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ced99a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_search(y_score, y_true):\n",
    "    y_score = np.asarray(y_score)\n",
    "    y_true = np.asarray(y_true)\n",
    "    best_acc = 0\n",
    "    best_th = 0\n",
    "    for i in range(len(y_score)):\n",
    "        th = y_score[i]\n",
    "        y_test = (y_score >= th)\n",
    "        acc = np.mean((y_test == y_true).astype(int))\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_th = th\n",
    "    return best_acc, best_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9dd691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(feature_dict, pair_list, test_root):\n",
    "    with open(pair_list, 'r') as f:\n",
    "        pairs = f.readlines()\n",
    "\n",
    "    similarities = []\n",
    "    labels = []\n",
    "    for pair in pairs:\n",
    "        img1, img2, label = pair.split()\n",
    "        img1 = osp.join(test_root, img1)\n",
    "        img2 = osp.join(test_root, img2)\n",
    "        feature1 = feature_dict[img1].cpu().numpy()\n",
    "        feature2 = feature_dict[img2].cpu().numpy()\n",
    "        label = int(label)\n",
    "\n",
    "        similarity = cosin_metric(feature1, feature2)\n",
    "        similarities.append(similarity)\n",
    "        labels.append(label)\n",
    "\n",
    "    accuracy, threshold = threshold_search(similarities, labels)\n",
    "    return accuracy, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ff384ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Model: checkpoints/myFMN_19_sample25%.pth\n",
      "Accuracy: 0.558\n",
      "Threshold: 0.772\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#for i in range(30):\n",
    "test_model = \"checkpoints/myFMN_\"+str(19)+\"_sample25%.pth\" #conf.test_model\n",
    "model = myFaceMobileNet(conf.embedding_size)\n",
    "model = nn.DataParallel(model)\n",
    "model.load_state_dict(torch.load(test_model, map_location=conf.device))\n",
    "model.eval()\n",
    "\n",
    "images = unique_image(conf.test_list)\n",
    "images = [osp.join(conf.test_root, img) for img in images]\n",
    "groups = group_image(images, conf.test_batch_size)\n",
    "\n",
    "feature_dict = dict()\n",
    "for group in groups:\n",
    "    d = featurize(group, conf.test_transform, model, conf.device,low_light = False)\n",
    "    feature_dict.update(d) \n",
    "accuracy, threshold = compute_accuracy(feature_dict, conf.test_list, conf.test_root) \n",
    "\n",
    "print(\n",
    "    f\"Test Model: {test_model}\\n\"\n",
    "    f\"Accuracy: {accuracy:.3f}\\n\"\n",
    "    f\"Threshold: {threshold:.3f}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88720da",
   "metadata": {},
   "source": [
    "# Get #params and FLOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e66505ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: module ConvBn is treated as a zero-op.\n",
      "Warning: module ConvBnPrelu is treated as a zero-op.\n",
      "Warning: module DepthWise is treated as a zero-op.\n",
      "Warning: module DepthWiseRes is treated as a zero-op.\n",
      "Warning: module MultiDepthWiseRes is treated as a zero-op.\n",
      "Warning: module Flatten is treated as a zero-op.\n",
      "Warning: module myFaceMobileNet is treated as a zero-op.\n",
      "Warning: module DataParallel is treated as a zero-op.\n",
      "Computational complexity:       557627392.0\n",
      "Number of parameters:           1916096 \n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(0):\n",
    "    #net = model\n",
    "    model = net\n",
    "    macs, params = get_model_complexity_info(net, (1,128,128), as_strings=False,\n",
    "                                           print_per_layer_stat=False, verbose=True)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs*2))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90ab100e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import myFaceMobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "954ec74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = myFaceMobileNet(conf.embedding_size)\n",
    "model = nn.DataParallel(model)\n",
    "#model.load_state_dict(torch.load(test_model, map_location=conf.device))\n",
    "#model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1981e39c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
