{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "474e277c",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10f17963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model import FaceMobileNet\n",
    "from model.metric import ArcFace, CosFace\n",
    "from model.loss import FocalLoss\n",
    "from dataset import load_data\n",
    "from config import Config as conf\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cfd04c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bef49f76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6024\\3662417422.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Course\\Graduate1\\Data_Science\\hw\\hw5\\dataset.py\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(conf, training)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mLabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "load_data(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fffc4fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"D:\\Course\\Graduate1\\Data_Science\\hw\\hw5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1d090b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Setup\n",
    "dataloader, class_num = load_data(conf, training=True)\n",
    "embedding_size = conf.embedding_size\n",
    "device = conf.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08bf47d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Setup\n",
    "net = FaceMobileNet(embedding_size).to(device)\n",
    "\n",
    "if conf.metric == 'arcface':\n",
    "    metric = ArcFace(embedding_size, class_num).to(device)\n",
    "else:\n",
    "    metric = CosFace(embedding_size, class_num).to(device)\n",
    "\n",
    "net = nn.DataParallel(net)\n",
    "metric = nn.DataParallel(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "131a4da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Setup\n",
    "if conf.loss == 'focal_loss':\n",
    "    criterion = FocalLoss(gamma=2)\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if conf.optimizer == 'sgd':\n",
    "    optimizer = optim.SGD([{'params': net.parameters()}, {'params': metric.parameters()}], \n",
    "                            lr=conf.lr, weight_decay=conf.weight_decay)\n",
    "else:\n",
    "    optimizer = optim.Adam([{'params': net.parameters()}, {'params': metric.parameters()}],\n",
    "                            lr=conf.lr, weight_decay=conf.weight_decay)\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=conf.lr_step, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9039da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoints Setup\n",
    "os.makedirs(conf.checkpoints, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5668236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/30: 100%|##########| 7119/7119 [14:31<00:00,  8.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/30, Loss: 14.636209487915039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|##########| 7119/7119 [14:30<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 13.404420852661133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|##########| 7119/7119 [14:30<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Loss: 12.529593467712402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|##########| 7119/7119 [14:30<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Loss: 11.526164054870605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|##########| 7119/7119 [14:30<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Loss: 11.17046070098877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|##########| 7119/7119 [14:29<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Loss: 9.362608909606934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|##########| 7119/7119 [14:29<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Loss: 10.645035743713379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|##########| 7119/7119 [14:28<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Loss: 10.336000442504883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|##########| 7119/7119 [14:30<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Loss: 9.285191535949707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|##########| 7119/7119 [14:28<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Loss: 9.937674522399902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|##########| 7119/7119 [14:28<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Loss: 7.436448574066162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|##########| 7119/7119 [14:28<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Loss: 7.5819902420043945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|##########| 7119/7119 [14:28<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Loss: 6.005134105682373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: 100%|##########| 7119/7119 [14:27<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30, Loss: 6.872140407562256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: 100%|##########| 7119/7119 [14:28<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30, Loss: 5.648280143737793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: 100%|##########| 7119/7119 [14:28<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30, Loss: 7.23828649520874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: 100%|##########| 7119/7119 [14:28<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30, Loss: 7.725142002105713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: 100%|##########| 7119/7119 [14:28<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30, Loss: 7.167911052703857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: 100%|##########| 7119/7119 [14:28<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30, Loss: 6.90154504776001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: 100%|##########| 7119/7119 [14:28<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30, Loss: 8.444781303405762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: 100%|##########| 7119/7119 [14:28<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30, Loss: 6.428404808044434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: 100%|##########| 7119/7119 [14:48<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30, Loss: 6.322268962860107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: 100%|##########| 7119/7119 [14:29<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30, Loss: 7.900283336639404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: 100%|##########| 7119/7119 [14:21<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30, Loss: 6.582077980041504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: 100%|##########| 7119/7119 [14:50<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30, Loss: 6.9685797691345215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: 100%|##########| 7119/7119 [15:11<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30, Loss: 7.759799480438232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: 100%|##########| 7119/7119 [15:19<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30, Loss: 4.772459983825684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30: 100%|##########| 7119/7119 [15:18<00:00,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30, Loss: 5.544327735900879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: 100%|##########| 7119/7119 [15:04<00:00,  7.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30, Loss: 5.775236129760742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: 100%|##########| 7119/7119 [14:53<00:00,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30, Loss: 6.29815149307251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "net.train()\n",
    "\n",
    "for e in range(conf.epoch):\n",
    "    for data, labels in tqdm(dataloader, desc=f\"Epoch {e}/{conf.epoch}\",\n",
    "                             ascii=True, total=len(dataloader)):\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        embeddings = net(data)\n",
    "        thetas = metric(embeddings, labels)\n",
    "        loss = criterion(thetas, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {e}/{conf.epoch}, Loss: {loss}\")\n",
    "\n",
    "    backbone_path = osp.join(conf.checkpoints, f\"{e}.pth\")\n",
    "    torch.save(net.state_dict(), backbone_path)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c280358e",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7582ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_image(pair_list) -> set:\n",
    "    \"\"\"Return unique image path in pair_list.txt\"\"\"\n",
    "    with open(pair_list, 'r') as fd:\n",
    "        pairs = fd.readlines()\n",
    "    unique = set()\n",
    "    for pair in pairs:\n",
    "        id1, id2, _ = pair.split()\n",
    "        unique.add(id1)\n",
    "        unique.add(id2)\n",
    "    return unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e031753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_image(images: set, batch) -> list:\n",
    "    \"\"\"Group image paths by batch size\"\"\"\n",
    "    images = list(images)\n",
    "    size = len(images)\n",
    "    res = []\n",
    "    for i in range(0, size, batch):\n",
    "        end = min(batch + i, size)\n",
    "        res.append(images[i : end])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24298711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess(images: list, transform, low_light = False) -> torch.Tensor:\n",
    "    res = []\n",
    "    for img in images:\n",
    "        im = Image.open(img)\n",
    "        if low_light:\n",
    "            im = (np.sqrt (im)*2).astype(np.uint8)\n",
    "            im = Image.fromarray(im)\n",
    "        im = transform(im)\n",
    "        res.append(im)\n",
    "    data = torch.cat(res, dim=0)  # shape: (batch, 128, 128)\n",
    "    data = data[:, None, :, :]    # shape: (batch, 1, 128, 128)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9156a2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize(images: list, transform, net, device,low_light = False) -> dict:\n",
    "    \"\"\"featurize each image and save into a dictionary\n",
    "    Args:\n",
    "        images: image paths\n",
    "        transform: test transform\n",
    "        net: pretrained model\n",
    "        device: cpu or cuda\n",
    "    Returns:\n",
    "        Dict (key: imagePath, value: feature)\n",
    "    \"\"\"\n",
    "    data = _preprocess(images, transform,low_light = low_light)\n",
    "    data = data.to(device)\n",
    "    net = net.to(device)\n",
    "    with torch.no_grad():\n",
    "        features = net(data) \n",
    "    res = {img: feature for (img, feature) in zip(images, features)}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30255a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosin_metric(x1, x2):\n",
    "    return np.dot(x1, x2) / (np.linalg.norm(x1) * np.linalg.norm(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ced99a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_search(y_score, y_true):\n",
    "    y_score = np.asarray(y_score)\n",
    "    y_true = np.asarray(y_true)\n",
    "    best_acc = 0\n",
    "    best_th = 0\n",
    "    for i in range(len(y_score)):\n",
    "        th = y_score[i]\n",
    "        y_test = (y_score >= th)\n",
    "        acc = np.mean((y_test == y_true).astype(int))\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_th = th\n",
    "    return best_acc, best_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9dd691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(feature_dict, pair_list, test_root):\n",
    "    with open(pair_list, 'r') as f:\n",
    "        pairs = f.readlines()\n",
    "\n",
    "    similarities = []\n",
    "    labels = []\n",
    "    for pair in pairs:\n",
    "        img1, img2, label = pair.split()\n",
    "        img1 = osp.join(test_root, img1)\n",
    "        img2 = osp.join(test_root, img2)\n",
    "        feature1 = feature_dict[img1].cpu().numpy()\n",
    "        feature2 = feature_dict[img2].cpu().numpy()\n",
    "        label = int(label)\n",
    "\n",
    "        similarity = cosin_metric(feature1, feature2)\n",
    "        similarities.append(similarity)\n",
    "        labels.append(label)\n",
    "\n",
    "    accuracy, threshold = threshold_search(similarities, labels)\n",
    "    return accuracy, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ff384ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Model: checkpoints/26.pth\n",
      "Accuracy: 0.945\n",
      "Threshold: 0.308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = FaceMobileNet(conf.embedding_size)\n",
    "model = nn.DataParallel(model)\n",
    "model.load_state_dict(torch.load(conf.test_model, map_location=conf.device))\n",
    "model.eval()\n",
    "\n",
    "images = unique_image(conf.test_list)\n",
    "images = [osp.join(conf.test_root, img) for img in images]\n",
    "groups = group_image(images, conf.test_batch_size)\n",
    "\n",
    "feature_dict = dict()\n",
    "for group in groups:\n",
    "    d = featurize(group, conf.test_transform, model, conf.device,low_light = False)\n",
    "    feature_dict.update(d) \n",
    "accuracy, threshold = compute_accuracy(feature_dict, conf.test_list, conf.test_root) \n",
    "\n",
    "print(\n",
    "    f\"Test Model: {conf.test_model}\\n\"\n",
    "    f\"Accuracy: {accuracy:.3f}\\n\"\n",
    "    f\"Threshold: {threshold:.3f}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78723ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
